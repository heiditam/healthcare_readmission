<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Hospital Readmission Rates</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
    <div id="progress-container">
        <div id="progress-bar"></div>
    </div>
  <div class="header-box">
    <h1>The Road to Recovery: <br> Predicting Hospital Readmissions</h1>
  </div>
  <!-- THE BUTTONS -->
  <div class="button-container">
    <button class='scroll-button' onclick="scrollToUnivariate()">📊 Univariate Analysis</button>
    <button class='scroll-button' onclick="scrollToBivariate()">🔗 Bivariate Analysis</button>
    <button class='scroll-button' onclick="scrollToPipeline()"> ⚙️ Pipeline Model</button>
    <a href="nlp.html"> <button class='scroll-button'>🧠 Word Embedding Analysis (NLP)</button></a>
  </div>


  <!-- CONTENT -->
  <div class="content">
    <p>👋🏻 Welcome to Heidi Tam's website dedicated to analyzing <strong>hospital readmission rates</strong>. This project explores patterns in patient encounters, identify high-risk cases, and uncover actionable insights to help healthcare providers reduce preventable readmissions.</p>

    <div class="highlight">
        👉🏻 <strong>Overview: </strong>This project aims to estimate hospital readmissions in order to reduce healthcare insurance costs and improve patient outcomes. The dataset used was the <i>Diabetes 130-US Hospitals for Years 1999-2008</i> dataset, found in the UC Irvine Machine Learning Repository. The dataset includes the hospital records of patients from 130 American hospitals who were diagnosed with diabetes and stayed for up to fourteen days.
        The dataset analyzed includes patient identifiers, demographic details, and admission characteristics, such as admission type, discharge disposition, and source of admission.
        Clinical details, such as length of hospital stay, number of lab procedures, medications administered, and diagnostic codes provide insight into the status of patient health and the level of patient care received.
        Finally, the dataset utilized covers diabetes-specific indicators, including blood glucose tests, medication usage, and changes in medication and overall diabetes management to assess risk of readmission with the true outcome.<br>
        👉🏻 <strong>Purpose:</strong> to identify the key predictors and patterns, aiming to accurately forecast whether patient will be readmitted within thirty days of discharge. The overarching goal is to improve 
        patient care outcomes and to minimize preventable returns to the hospital. 
    </div>
    <p>This project includes interactive dashboards, statistical models, and policy recommendations aimed at transforming patient care outcomes across the U.S. healthcare system. <br> Continue reading to learn more! 👇🏻</p>
  </div>

<!-- UNIVARIATE ANALYSIS -->
<div class="panel" id = 'Univariate Analysis'>
    <h1>Univariate Analysis</h1>
    <div class="sections-container">
        <div class="section"><h2>Demographic Variables</h2>
            <iframe src = 'race_bar_graph.html' width="600" height = "500"></iframe>
            <ul>
                <li>Almost <strong>3/4</strong> of the patients were Caucasian.</li>
                <li><strong>53.76%</strong> female and <strong>46.24%</strong> male patients</li>
                <li>Most common age group: <strong>seniors</strong> and older adults, with 47.7% of patients falling between ages 60-80.</li>
                <li>The vast majority, about 60%, discharged to home.</li>
                <li>More than half of encounters were admitted through the <strong>emergency room.</strong></li>
                <li>On average, patients spent about <strong>4.4 days in the hospital.</strong> </li>
                <li>About 1 in 10 encounters resulted in <strong>readmittance</strong>.</li>
            </ul>
        </div>
        <div class="section"><h2>Clinical Procedures, Visits, Diagnoses</h2>
          <iframe src="lab_proc_graph.html" width="600" height="500"></iframe>
          <ul>
            <li>The data ranges from 1 to 132 lab procedures, with the <strong>middle 50% having 31 to 57 lab procedures</strong>. On average, patients had about 43.1 lab procedures.</li>
            <li>Typically, patients only have <strong>about 1.34 other procedures.</strong></li>
            <li>The number of medications prescribed ranges from 1 to 81, with the <strong>middle 50% having 10 to 20 medications prescribed.</strong> On average, patients were prescribed 16 medications.</li>
            <li>15.76% of patients had at least one outpatient visit, 9.98% had at least one emergency visit, and 29.39% had at least one inpatient visit.</li>
            <li>On average, there were about <strong>7.42 diagnoses per encounter.</strong></li>
            <li>The top 10 most common first diagnoses were: heart failure, chronic osemic heart disease, symptoms involving the respiratory system and other chest symptoms, acute myocardial infarction, pneumonia, conduction disorders, osteoarthritis, other cellulitis and abscess, and occlusion of cerebral arteries.</li>
          </ul>
        </div>
        <div class="section"><h2>Diabetes-Related Tests & Medications</h2>
          <iframe src="max_glu_graph.html" width="600" height="500"></iframe>
        </div>
        <div class="section">
          <h2>👈🏻 Diabetes-Related Tests & Medications</h2>
          <ul>
            <li>Glucose serum was <strong>tested about 5.25%</strong> of the time. Almost half the results were normal. The remaining patients had a maximum glucose serum of at least 200, suggesting they have diabetes.</li>
            <li>The most common prescribed drugs were insulin (54,383), metformin (19,988), glipizide (12,686), glyburide (10,650), and pioglitazone (7,328).</li>
            <li>The most commonly used combination medication was glyburide-metformin (706).</li>
            <li>There was a change in medication about <strong>46.2%</strong> of the time.</li>
            <li>About <strong>59.4% of the patients on diabetes medication.</strong></li>
          </ul>
        </div>
    </div>  
</div>
<!-- BIVARIATE ANALYSIS -->
 <div class="panel" id="Bivariate Analysis">
    <h1>Bivariate Analysis</h1>
    <div class="sections-container">
      <div class="section">
        <h2>Groups At Risk</h2>
        <iframe src = 'age_readmission.html' width="600" height="500"></iframe>
        <p>After conducting a <strong>Chi-Squared Test for Independence</strong>, we retrieved a chi-squared statistic of about 116.609 and a <strong>p-value of about 6.6 * 10^(-21)</strong>
        Since the p-value is less than the threshold of 0.05, we reject the null hypothesis that there is no association between readmission rate and age.
       In other words, there is <strong>statistically significant evidence of an association</strong> between age and readmission.
       From the graph, 20-30-year-olds have the highest likelihood of readmission (14.24% readmitted) compared to 0-10-year-olds, which had the lowest rate, at 1.86%.</p>
      </div>
      <div class="section">
        <h2>Treatment Impact</h2>
        Using a Chi-Squared contingency table, some of the medications significantly linked with higher readmission were insulin, metformin, and repaglinide. <br> <br>
        <img src="insulin_odds_ratios.png" alt="Insulin Odds Ratio" width="600" height="400"> 
        <br><br>
        From a <strong>Logit Regression Analysis:</strong>
        <ul>
          <li>Patients with <strong>steady insulin</strong> have <strong>12% higher odds</strong> of readmission than those not on insulin.</li>
          <li>Patients with <strong>increasing insulin</strong> dosage have <strong>34% higher odds</strong> of readmission.</li>
          <li>Patients with <strong>decreasing insulin</strong> have <strong>45% higher odds</strong> of readmission.</li>
        </ul>
      </div>
      <div class="section">
        <h2>Clinical Insight</h2>
        <iframe src="max_glu_fig.html" width="600" height="500"></iframe>
        <p>A <strong>Chi Square Test of Independence</strong> between maximum glucose serum levels and readmitted rates yielded a chi-squared value of about 6.89 and a <strong>p-value of 0.03.</strong>
        Since the p-value is less than the threshold of 0.05, there is a significant difference of readmission rates between each glucose serum level (normal, > 200, and > 300).
       In this visualization, the yellow dotted line represents the proportion of encounters with a normal glucose serum level that resulted in readmittance: about 11.36%.
       From the graph, the readmittance rate for > 200 was slightly higher, reaching 12.46%. The <strong>readmittance rate for > 300 was notably higher</strong> than the yellow line, reaching 14.32% readmitted.
       In other words, the more glucose serum a patient's blood contained was associated with <strong>a greater likelihood of being readmitted</strong> into the hospital.</p>
      </div>
      <div class='section'>
        <h2>Discharge & Follow-Up Issues</h2>
        <iframe src="patient_discharge.html" width="600" height="500"></iframe>
        <p>Ignoring instances where the location of patience discharge was unknown or unclassified, the top three locations of patient discharge were <strong>home, a skilled nursing facility</strong>, or discharged/transferred to a home with <strong>home health services.</strong>
        Conducting another <strong>Chi-Squared Test of Independence</strong>, it is evident there is a very strong assocation between discharge dispostion and readmission.
       For example, patients discharged to go home or a skilled nursing facility had readmission rates of about 9.30% and 14.66%, respectively. In contrast, being discharged with "still 
       patient or expected to return for outpatient services" resulted in a whopping readmission rate of 66.67%; 2 in 3 people discharged with this status had to be readmitted to the hospital.</p>
      </div>
    </div>
 </div>

 <!-- PIPELINE MODELLING -->
  <div class="panel" id="Pipeline Model">
    <h1>Pipeline Model</h1>
    <div class="content">
      <div class = 'highlight'>
        <h2>Baseline Model</h2>
        Initially, I used <strong>Logistic Regression</strong> to establish a baseline for comparison since it's simple, quick to train, and easily interpretable.<br>
        <pre>
                  precision    recall  f1-score   support

              0       0.92      0.69      0.79      9039
              1       0.18      0.55      0.27      1135

       accuracy                           0.67     10174
      macro avg       0.55      0.62      0.53     10174
   weighted avg       0.84      0.67      0.73     10174

        ROC AUC: 0.674763153110871
        </pre>
        The logistic regression model does well classifying data points that are <em>not</em> hospital readmissions (class 0), but does very poorly classifying those that are (class 1).
        However, in this situation, Class 1 is the significant class we want to pay attention to. The <strong>high recall (0.55)</strong> is promising because it suggests over half of the 
        positive cases are caught, although many data points are misclassified. The <strong>precision (0.18)</strong>, however, is very low, suggesting a lot of false positives.
      </div>
      <h2>Advanced Model</h2>
      For the advanced model, I used <strong>Random Forest</strong> as a stronger metric due to its ability to model nonlinear relationships. Random forest models have the power of building multiple decision trees during training and outputs the mode of their predictions. This method generally 
      improves predictive performance while reducing overfitting. To ensure diversity among the trees, it uses bagging (bootstrap aggregation) and random feature selection. I selected 
      Random Forest because it has the ability to <strong>handle imbalanced data</strong> and is <strong>robust to noisy features</strong>. It also has the ability to capture complex
      interactions without heavy preprocessing.<br>
      I used the following hyperparameters in my model:<br>
      <pre><code>
        rf_model = RandomForestClassifier(
          n_estimators=100,
          max_depth=None,
          class_weight='balanced', 
          random_state=42
        )
      </code></pre>
      class_weight was set to 'balanced' to address the class imbalance between readmissions (which was only about 11% of the dataset) and patients who were not readmitted.
      Although the model achieved an accuracy of 0.89, which was greater than its logistic regression model's counterpart of 0.67, the Random Forest model had a <strong>recall score of only 0.01</strong>. In other words, 
      the model is only useful for catching 1% of hospital readmissions, ultimately failing its designated purpose. Its <strong>F1-Score was also 0.02</strong>, supporting the idea that the model is not useful for predicting hospital
      readmissions. Thus, the high accuracy of 89% is misleading. Instead of demonstrating the model's strong performance, it highlights the disparity between the number of 
      readmissions and non-readmissions in the hospitals. Additionally, the ROC-AUC of 0.65 suggests <strong>the model is only slightly better than random guessing</strong>,
      which would result in an ROC-AUC of 0.5.<br>
      Then, I used an <strong>XGBoost Model</strong> in hopes of achieving strong predictive accuracy while minimizing bias and variance. Once again, the validation accuracy was 0.89, but the recall was 0.00. Once again, the majority class (negatives)
      dominated, which makes the minority class underestimated more often. The model is almost never correct when identifying when a patient needs to be readmitted in under 30 days. As a result, the <strong>F1-Score was only 0.01</strong> due to poor
      positive class detection. This appears to be a central issue with this dataset; since only 11% of the data had hospital readmissions, the dataset was highly imbalanced, indicating we need to adjust hyperparameters more thoroughly and not solely 
      rely on observing accuracy.
      <div class="highlight">
        <h2>Hyperparameter Tuning</h2>
        <p>Using <strong>Grid Search CV</strong>, I found the most optimal hyperparameters to be:</p>
        <pre><code>
          xgb_model = XGBClassifier(
            subsample= 0.7956447755377811,
            n_estimators = 527,
            min_child_weight = 2,
            max_depth = 3,
            learning_rate = 0.037281761570859454,
            colsample_bytree = 0.8093574700581173,
            scale_pos_weight = 5,
            use_label_encoder = False,
            eval_metric = 'logloss',
            random_state = 42
          )
        </code></pre>
        <strong>The goal is to maximize our F1 score</strong>, so I found a threshold that would achieve this goal. Using a thrsehold of 0.443, we obtain the following metrics:
        <ul>
          <li><strong>Precision:</strong> 0.21 (validation) or 0.20 (test)</li>
          <li><strong>Recall: </strong>0.46 (validation) or 0.44 (test)</li>
          <li><strong>F1-Score: </strong>0.29 (validation) or 0.28 (test)</li>
          <li><strong>Accuracy: </strong>0.75 on both validation/test Sets</li>
        </ul>
        <strong>Precision</strong> measures how <em>accurate</em> our predictions are, and <strong>recall</strong> measures how <em>complete</em> they are.
        For optimal performance, we would ideally like a high precision and high recall, which is measured with the F1-Score, the harmonic mean of both. In this case,
        we want to identify as many patients who will be readmitted in under 30 days (high recall) while not flagging too many patients that will not return in less than 30 days 
        (high precision).
      </div>
      <h2>Class Imbalances</h2>
      Since hospital readmissions only made up 11% of the data, there was a strong imbalance of classes. I tried to handle class imbalances by employing two very powerful 
      techniques designated for class imbalances: <strong>SMOTE and ADASYN</strong>. However, neither of these improved XGBoost's F1-Score of 0.29, potentially due to poor class separability. If the minority and majority
       classes are not well-separated, synthetic examples created by SMOTE or ADASYN may fall into regions dominated by the majority class, causing more overlap between the classes
       and worse precision. Additionally, the minority class may have been too sparse, causing the synthetic data SMOTE creates to be of little use. While ADASYN focuses on 
       examples that are generally difficult to learn, it may also amplify noise by oversampling outliers or borderline points, harming the model's performance.
    </div>
  </div>

  <!-- FOOTER -->
  <footer>
    &copy; 2025 Heidi Tam. All rights reserved.
  </footer>
  <!-- FOR THE PROGRESS BAR -->
  <script>
    window.onscroll = function () {
      updateProgressBar();
    };
  
    function updateProgressBar() {
      const winScroll = document.documentElement.scrollTop || document.body.scrollTop;
      const height = document.documentElement.scrollHeight - document.documentElement.clientHeight;
      const scrolled = (winScroll / height) * 100;
      document.getElementById("progress-bar").style.width = scrolled + "%";
    }
  </script>
  <!-- FOR THE UNIVARIATE SCROLL BUTTON -->
  <script>
    function scrollToUnivariate() {
      const target = document.getElementById('Univariate Analysis');
      target.scrollIntoView({ behavior: 'smooth' });
    }
    function scrollToBivariate(){
      const target = document.getElementById('Bivariate Analysis');
      target.scrollIntoView({behavior: 'smooth'});
    }

    function scrollToPipeline(){
      const target = document.getElementById('Pipeline Model');
      target.scrollIntoView({behavior: 'smooth'});
    }

    function scrollToTop(){
      window.scrollTo({top:0, behavior:'smooth'});
    }

    const btn = document.getElementById("backToTopBtn");

    window.onscroll = function() {
      if (document.body.scrollTop > 300 || document.documentElement.scrollTop > 300) {
        btn.style.display = "block";
      } else {
        btn.style.display = "none";
      }
    };
  </script>
  <button id="backToTopBtn" onclick="scrollToTop()">👆🏻 Top</button>
</body>
</html>
